{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "za8ATvr1D7Bu",
        "outputId": "89061584-7495-4c86-e522-22a8b8148aa9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pymupdf\n",
            "  Downloading pymupdf-1.26.7-cp310-abi3-manylinux_2_28_x86_64.whl.metadata (3.4 kB)\n",
            "Collecting groq\n",
            "  Downloading groq-1.0.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from groq) (4.12.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from groq) (2.12.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.12/dist-packages (from groq) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->groq) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (0.4.2)\n",
            "Downloading pymupdf-1.26.7-cp310-abi3-manylinux_2_28_x86_64.whl (24.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m40.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading groq-1.0.0-py3-none-any.whl (138 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.3/138.3 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pymupdf, groq\n",
            "Successfully installed groq-1.0.0 pymupdf-1.26.7\n"
          ]
        }
      ],
      "source": [
        "# Installing dependencies for PDF processing and Groq API\n",
        "!pip install pymupdf groq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cRxLttZZEE0t",
        "outputId": "caa19b79-1326-48e5-a6ae-9a9c56829aac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Environment variable set!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "# Setting the key for the session\n",
        "os.environ[\"GROQ_API_KEY\"] = \"please give yout groq api key here\"\n",
        "print(\"Environment variable set!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_hp3-GAbElRd"
      },
      "source": [
        "Experiment: Handling Unstructured Hospital Data\n",
        "\n",
        "I wanted to see if the model could tell the difference between \"Doctor Notes\" and \"Medical History\" without getting them mixed up."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SYVhOLTgE3Xt",
        "outputId": "61cc1603-c25b-4fab-d687-46f4d6e0a85e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Holistic Result:\n",
            " Based on the provided patient data, here's a comparison of the ages and admission dates:\n",
            "\n",
            "1. **Lakshmi Narayan**:\n",
            "   - Age: 61\n",
            "   - Admission Date: 12 Aug 2024\n",
            "\n",
            "2. **Neha Sharma**:\n",
            "   - Age: 29\n",
            "   - Admission Date: 14 Aug 2024\n",
            "\n",
            "3. **Mohammed Irfan**:\n",
            "   - Age: 38\n",
            "   - Admission Date: 16 Aug 2024\n",
            "\n",
            "Comparing the ages:\n",
            "- Lakshmi Narayan is the oldest at 61 years.\n",
            "- Mohammed Irfan is in the middle at 38 years.\n",
            "- Neha Sharma is the youngest at 29 years.\n",
            "\n",
            "Comparing the admission dates:\n",
            "- Lakshmi Narayan was admitted first on 12 Aug 2024.\n",
            "- Neha Sharma was admitted second on 14 Aug 2024.\n",
            "- Mohammed Irfan was admitted last on 16 Aug 2024.\n"
          ]
        }
      ],
      "source": [
        "from groq import Groq\n",
        "import os\n",
        "\n",
        "client = Groq(api_key=os.environ.get(\"GROQ_API_KEY\"))\n",
        "\n",
        "#specific hospital data from the PDFs\n",
        "combined_context = \"\"\"\n",
        "[DOC 1]: Lakshmi Narayan, Age 61, Admitted 12 Aug 2024, ECG abnormal.\n",
        "[DOC 2]: Neha Sharma, Age 29, Admitted 14 Aug 2024, Suspected gastritis.\n",
        "[DOC 3]: Mohammed Irfan, Age 38, Admitted 16 Aug 2024, Suspected viral fever.\n",
        "\"\"\"\n",
        "\n",
        "# Fixed Query: Removed the variable name from the string\n",
        "query = \"Compare the ages and admission dates of all patients.\"\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    messages=[\n",
        "        # Human-style fix: Clearly tell the AI what the context is\n",
        "        {\"role\": \"system\", \"content\": f\"Use the following patient data to answer: {combined_context}\"},\n",
        "        {\"role\": \"user\", \"content\": query}\n",
        "    ],\n",
        "    model=\"llama-3.1-8b-instant\",\n",
        "    temperature=0.1 # Keeps it factual to avoid hallucinations\n",
        ")\n",
        "\n",
        "print(\"Holistic Result:\\n\", response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDg6aFIUHexU",
        "outputId": "52aa7de4-a480-41a2-f556-3fee378e493d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Holistic Result (Temp 0):\n",
            " Based on the provided data, here's a comparison of the ages and admission dates of all patients:\n",
            "\n",
            "1. **Lakshmi Narayan**:\n",
            "   - Age: 61\n",
            "   - Admission Date: 12 Aug 2024\n",
            "\n",
            "2. **Neha Sharma**:\n",
            "   - Age: 29\n",
            "   - Admission Date: 14 Aug 2024\n",
            "\n",
            "3. **Mohammed Irfan**:\n",
            "   - Age: 38\n",
            "   - Admission Date: 16 Aug 2024\n",
            "\n",
            "Comparing the ages:\n",
            "- The youngest patient is **Neha Sharma** with an age of 29.\n",
            "- The oldest patient is **Lakshmi Narayan** with an age of 61.\n",
            "- **Mohammed Irfan** is in between with an age of 38.\n",
            "\n",
            "Comparing the admission dates:\n",
            "- The earliest admission date is **Lakshmi Narayan** on 12 Aug 2024.\n",
            "- The latest admission date is **Mohammed Irfan** on 16 Aug 2024.\n",
            "- **Neha Sharma** was admitted on 14 Aug 2024, which is in between the two dates.\n"
          ]
        }
      ],
      "source": [
        "from groq import Groq\n",
        "import os\n",
        "\n",
        "client = Groq(api_key=os.environ.get(\"GROQ_API_KEY\"))\n",
        "\n",
        "# The data from your specific hospital PDFs\n",
        "combined_context = \"\"\"\n",
        "[DOC 1]: Lakshmi Narayan, Age 61, Admitted 12 Aug 2024.\n",
        "[DOC 2]: Neha Sharma, Age 29, Admitted 14 Aug 2024.\n",
        "[DOC 3]: Mohammed Irfan, Age 38, Admitted 16 Aug 2024.\n",
        "\"\"\"\n",
        "\n",
        "# The Query\n",
        "query = \"Compare the ages and admission dates of all patients.\"\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": f\"You are a factual agent. Use this data: {combined_context}\"},\n",
        "        {\"role\": \"user\", \"content\": query}\n",
        "    ],\n",
        "    model=\"llama-3.1-8b-instant\",\n",
        "    temperature=0.5 # Forced deterministic output to prevent hallucinations\n",
        ")\n",
        "\n",
        "print(\"Holistic Result (Temp 0):\\n\", response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BAkyd_4SHxai",
        "outputId": "5bf02aa2-0742-4a0c-93a2-6ebaf4e48d67"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Holistic Result (Temp 0):\n",
            " Based on the provided data, here's a comparison of the ages and admission dates of all patients:\n",
            "\n",
            "**Age Comparison:**\n",
            "\n",
            "1. Lakshmi Narayan - 61 years old\n",
            "2. Neha Sharma - 29 years old\n",
            "3. Mohammed Irfan - 38 years old\n",
            "\n",
            "- Neha Sharma (29) is the youngest patient.\n",
            "- Mohammed Irfan (38) is younger than Lakshmi Narayan (61).\n",
            "- Lakshmi Narayan (61) is the oldest patient.\n",
            "\n",
            "**Admission Dates:**\n",
            "\n",
            "1. Lakshmi Narayan - 12 Aug 2024\n",
            "2. Neha Sharma - 14 Aug 2024\n",
            "3. Mohammed Irfan - 16 Aug 2024\n",
            "\n",
            "- Lakshmi Narayan was admitted first on 12 Aug 2024.\n",
            "- Neha Sharma was admitted two days later, on 14 Aug 2024.\n",
            "- Mohammed Irfan was admitted two days after Neha Sharma, on 16 Aug 2024.\n"
          ]
        }
      ],
      "source": [
        "from groq import Groq\n",
        "import os\n",
        "\n",
        "client = Groq(api_key=os.environ.get(\"GROQ_API_KEY\"))\n",
        "\n",
        "# The data from your specific hospital PDFs\n",
        "combined_context = \"\"\"\n",
        "[DOC 1]: Lakshmi Narayan, Age 61, Admitted 12 Aug 2024.\n",
        "[DOC 2]: Neha Sharma, Age 29, Admitted 14 Aug 2024.\n",
        "[DOC 3]: Mohammed Irfan, Age 38, Admitted 16 Aug 2024.\n",
        "\"\"\"\n",
        "\n",
        "# The Query\n",
        "query = \"Compare the ages and admission dates of all patients.\"\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": f\"You are a factual agent. Use this data: {combined_context}\"},\n",
        "        {\"role\": \"user\", \"content\": query}\n",
        "    ],\n",
        "    model=\"llama-3.1-8b-instant\",\n",
        "    temperature=1  # Forced deterministic output to prevent hallucinations\n",
        ")\n",
        "\n",
        "print(\"Holistic Result (Temp 0):\\n\", response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tMYSyaBiIWxO"
      },
      "source": [
        "1. Temperature 0: The \"Factual\" Baseline\n",
        "\n",
        "2. Temperature 0.5: The \"Balanced\" Output\n",
        "Observation:noticed the AI started adding descriptive phrases like \"Mohammed Irfan is in between\" or \"earliest admission date.\"\n",
        "\n",
        "3. Temperature 1.0: The \"Creative\" Narrative\n",
        "Observation: The AI began calculating the time between dates (e.g., \"admitted two days later\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IAVqElnlI199",
        "outputId": "3b0d0aab-ce40-4e3e-f444-e7994643cee9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Running Zero-Shot ---\n",
            "Here's the list of patient names:\n",
            "\n",
            "1. Lakshmi Narayan\n",
            "2. Neha Sharma\n",
            "3. Mohammed Irfan\n",
            "\n",
            "--- Running Few-Shot ---\n",
            "[DOC 1]: LAKSHMI NARAYAN | 61\n",
            "[DOC 2]: NEHA SHARMA | 29\n",
            "[DOC 3]: MOHAMMED IRFAN | 38\n",
            "\n",
            "--- Running Chain-of-Thought ---\n",
            "To determine the oldest patient and the age difference between the oldest and the youngest, I will analyze the data step by step:\n",
            "\n",
            "1. Identify the ages of all patients:\n",
            "   - Lakshmi Narayan: 61 years\n",
            "   - Neha Sharma: 29 years\n",
            "   - Mohammed Irfan: 38 years\n",
            "\n",
            "2. Determine the oldest patient:\n",
            "   - The oldest patient is Lakshmi Narayan, who is 61 years old.\n",
            "\n",
            "3. Identify the youngest patient:\n",
            "   - The youngest patient is Neha Sharma, who is 29 years old.\n",
            "\n",
            "4. Calculate the age difference between the oldest and the youngest:\n",
            "   - Age difference = Age of oldest patient - Age of youngest patient\n",
            "   - Age difference = 61 - 29\n",
            "   - Age difference = 32 years\n",
            "\n",
            "Therefore, the oldest patient is Lakshmi Narayan, and they are 32 years older than the youngest patient, Neha Sharma.\n"
          ]
        }
      ],
      "source": [
        "from groq import Groq\n",
        "import os\n",
        "\n",
        "client = Groq(api_key=os.environ.get(\"GROQ_API_KEY\"))\n",
        "\n",
        "# The data from your specific hospital PDFs\n",
        "combined_context = \"\"\"\n",
        "[DOC 1]: Lakshmi Narayan, Age 61, Admitted 12 Aug 2024.\n",
        "[DOC 2]: Neha Sharma, Age 29, Admitted 14 Aug 2024.\n",
        "[DOC 3]: Mohammed Irfan, Age 38, Admitted 16 Aug 2024.\n",
        "\"\"\"\n",
        "\n",
        "def run_prompt_experiment(technique, system_msg, user_msg):\n",
        "    print(f\"\\n--- Running {technique} ---\")\n",
        "    response = client.chat.completions.create(\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": system_msg},\n",
        "            {\"role\": \"user\", \"content\": user_msg}\n",
        "        ],\n",
        "        model=\"llama-3.1-8b-instant\",\n",
        "        temperature=0\n",
        "    )\n",
        "    print(response.choices[0].message.content)\n",
        "\n",
        "# 1. ZERO-SHOT (Direct request, no examples)\n",
        "zero_shot_sys = \"You are a factual assistant. Answer strictly based on context.\"\n",
        "zero_shot_user = f\"List all patient names from this data: {combined_context}\"\n",
        "run_prompt_experiment(\"Zero-Shot\", zero_shot_sys, zero_shot_user)\n",
        "\n",
        "# 2. FEW-SHOT (Giving an example of the desired format)\n",
        "few_shot_sys = \"You are an extractor. Follow the user's example format exactly.\"\n",
        "few_shot_user = f\"\"\"\n",
        "Example: [NAME] | [AGE]\n",
        "Data: [DOC 1]: Lakshmi Narayan, Age 61.\n",
        "Output: LAKSHMI NARAYAN | 61\n",
        "\n",
        "Now do the same for all patients in this data: {combined_context}\n",
        "\"\"\"\n",
        "run_prompt_experiment(\"Few-Shot\", few_shot_sys, few_shot_user)\n",
        "\n",
        "# 3. CHAIN-OF-THOUGHT (Thinking step-by-step to prevent logic errors)\n",
        "cot_sys = \"You are a logical analyst. Think step-by-step before answering.\"\n",
        "cot_user = f\"\"\"\n",
        "Data: {combined_context}\n",
        "Question: Who is the oldest patient and how many years older are they than the youngest?\n",
        "\"\"\"\n",
        "run_prompt_experiment(\"Chain-of-Thought\", cot_sys, cot_user)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gKheiAqZJgUs"
      },
      "source": [
        "Developer Note: Prompt Strategy Findings\n",
        "\n",
        "Zero-Shot: Used for general QA; it provides direct answers but can sometimes be wordy.\n",
        "\n",
        "Few-Shot: Best for Extraction; providing a single example format (e.g., Name | Age) ensures the agent outputs data in a clean, predictable structure .\n",
        "\n",
        "Chain-of-Thought (CoT): Essential for Holistic Insights; forcing the model to \"think step-by-step\" ensures accurate comparisons between patients (like age gaps) and effectively rectifies hallucinations"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
